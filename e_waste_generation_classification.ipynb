{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Soniya43-k/AICTE-Internship/blob/main/e_waste_generation_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72c59d5e-1662-4783-b985-a6188ce8fb11",
      "metadata": {
        "id": "72c59d5e-1662-4783-b985-a6188ce8fb11"
      },
      "source": [
        "\n",
        "\n",
        "#  E-Waste Image Classification Using EfficientNetV2B0 (Transfer Learning)\n",
        "\n",
        "\n",
        "\n",
        "##  Problem Statement and Description\n",
        "\n",
        "E-waste (electronic waste) is rapidly becoming a serious environmental and health issue around the world. Proper sorting and categorization of e-waste is essential for efficient recycling and disposal, but manual classification is error-prone and labor-intensive.\n",
        "\n",
        "This project aims to build an automated e-waste classification system using artificial intelligence and machine learning. By training a deep learning model on images of different types of e-waste, we can identify and categorize them accurately.\n",
        "\n",
        "###  Goal:\n",
        "Use image classification with EfficientNetV2B0 to classify e-waste into 10 distinct categories to support better sorting and recycling automation.\n",
        "\n",
        "---\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6025b85b-5934-49ee-b04f-02e23ab93544",
      "metadata": {
        "id": "6025b85b-5934-49ee-b04f-02e23ab93544"
      },
      "source": [
        "\n",
        "\n",
        "##  Dataset Overview\n",
        "\n",
        "###  Dataset Name: E-Waste Image Dataset  \n",
        "###  Source:  https://www.kaggle.com/datasets/akshat103/e-waste-image-dataset\n",
        "\n",
        "Each directory contains 10 subfolders, each representing one class of e-waste:\n",
        "\n",
        "- PCB (Printed Circuit Board)\n",
        "- Player\n",
        "- Battery\n",
        "- Microwave\n",
        "- Mobile\n",
        "- Mouse\n",
        "- Printer\n",
        "- Television\n",
        "- Washing Machine\n",
        "- Keyboard\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e6e3zdVOfU5R"
      },
      "id": "e6e3zdVOfU5R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "6ea58d19-c016-45d1-ac53-f616be417ede",
      "metadata": {
        "id": "6ea58d19-c016-45d1-ac53-f616be417ede"
      },
      "source": [
        "![image.png](attachment:5fe4e2cd-166c-4a06-93db-01d11bd9d78a.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c74a0f55-ce2b-4d07-8d60-aebd530a4e79",
      "metadata": {
        "id": "c74a0f55-ce2b-4d07-8d60-aebd530a4e79"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "##  What is Transfer Learning?\n",
        "\n",
        "Transfer Learning: Transfer Learning is a machine learning technique where a pre-trained model developed for a specific task is reused as the starting point for a model on a different but related task. It also allows us to build accurate models in a time-saving way by starting from patterns learned when solving a different problem. This approach is beneficial when there is limited data for the new task, as the pre-trained model already has learned features that can be adapted. Transfer learning can significantly improve models' performance and efficiency in domains like computer vision and natural language processing.\n",
        "\n",
        "###  Benefits\n",
        "-  **Reduces training time** — you don't start from scratch.\n",
        "-  **Leverages learned features** from large datasets (like ImageNet).\n",
        "-  **Improves performance**, especially with limited data.\n",
        "\n",
        "---\n",
        "\n",
        "##  How Does It Work?\n",
        "\n",
        "1.  Load a pretrained model (e.g., ResNet, EfficientNet).\n",
        "2.  **Freeze** the pretrained layers (optional).\n",
        "3.  Add new layers for your custom task.\n",
        "4.  Train on your new dataset (can also fine-tune).\n",
        "\n",
        "---\n",
        "\n",
        "#  EfficientNetV2B0: Transfer Learning Backbone\n",
        "\n",
        "##  Overview\n",
        "\n",
        "EfficientNetV2 is an optimized family of models introduced by Google for efficient training and inference.\n",
        "\n",
        "###  Key Features:\n",
        "-  Fused MBConv blocks — improve training speed and GPU efficiency.\n",
        "-  Progressive learning — gradually increases input size during training.\n",
        "-  Better accuracy with fewer parameters and FLOPs.\n",
        "\n",
        "---\n",
        "\n",
        "##  Why Use EfficientNetV2B0?\n",
        " -  Lightweight - Small model size, ideal for mobile & edge devices\n",
        " -  Fast - Quick training and inference           \n",
        " -  Pretrained on ImageNet - Excellent feature extraction baseline             \n",
        " -  High Accuracy - Competitively performs even in low-resource setups\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca4fc51c-735d-409b-a69e-2d16b5556f9c",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca4fc51c-735d-409b-a69e-2d16b5556f9c",
        "outputId": "42140389-f4d9-476b-f311-32fa6e615452"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.6.15)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "# Install TensorFlow package\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6a2d997-d500-4983-8793-deb362bc0d74",
      "metadata": {
        "id": "d6a2d997-d500-4983-8793-deb362bc0d74"
      },
      "source": [
        "###  Core Libraries\n",
        "- `tensorflow`: For deep learning model building and training.\n",
        "- `numpy`: For numerical operations and array manipulation.\n",
        "- `matplotlib.pyplot`: For plotting training curves and results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "315b6b4c-9f51-4106-8ebb-804025647d1d",
      "metadata": {
        "id": "315b6b4c-9f51-4106-8ebb-804025647d1d"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf  # Core TensorFlow library\n",
        "\n",
        "from tensorflow.keras import layers, models, optimizers, callbacks  # Layers, model creation, optimizers, and training callbacks\n",
        "\n",
        "from tensorflow.keras.models import Sequential, load_model  # For sequential model architecture and loading saved models\n",
        "\n",
        "from tensorflow.keras.applications import EfficientNetV2B0  # Pretrained EfficientNetV2B0 model for transfer learning\n",
        "\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input  # Preprocessing function specific to EfficientNet\n",
        "\n",
        "import numpy as np  # Numerical operations and array handling\n",
        "\n",
        "import matplotlib.pyplot as plt  # Plotting graphs and images\n",
        "\n",
        "import seaborn as sns  # Plotting graphs and images\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report  # Evaluation metrics for classification models\n",
        "\n",
        "import gradio as gr  # Web interface library to deploy and test ML models\n",
        "\n",
        "from PIL import Image  # For image file loading and basic image operations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acedf259-4f78-41b3-877f-bb4b8c83cb1f",
      "metadata": {
        "id": "acedf259-4f78-41b3-877f-bb4b8c83cb1f"
      },
      "source": [
        "###  Format: Folder-based image classification dataset  \n",
        "- `Train/`: Images used for training the model  \n",
        "- `Test/`: Images used for model evaluation  \n",
        "- `Validation/`: Images used to fine-tune and validate the model  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "175c89e0-eb62-4c0e-a00b-a1fca09d9235",
      "metadata": {
        "id": "175c89e0-eb62-4c0e-a00b-a1fca09d9235"
      },
      "outputs": [],
      "source": [
        "testpath= r'C:\\Users\\Edunet Foundation\\Downloads\\project\\E waste data\\modified-dataset\\test'\n",
        "trainpath= r'C:\\Users\\Edunet Foundation\\Downloads\\project\\E waste data\\modified-dataset\\train'\n",
        "validpath = r'C:\\Users\\Edunet Foundation\\Downloads\\project\\E waste data\\modified-dataset\\val'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10128ebb-7a66-44d3-ad3a-939a413b4717",
      "metadata": {
        "id": "10128ebb-7a66-44d3-ad3a-939a413b4717"
      },
      "source": [
        "## 1.  Explore and Understand the Data\n",
        "- Load image dataset using tools like `image_dataset_from_directory`.\n",
        "- Visualize sample images from each class.\n",
        "- Check the number of images per class to ensure balance.\n",
        "- Understand image dimensions, color channels, and class labels.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1d1e0d2-ecc5-46ff-a9fe-b4f82c77348f",
      "metadata": {
        "id": "d1d1e0d2-ecc5-46ff-a9fe-b4f82c77348f"
      },
      "source": [
        "\n",
        "### Load image dataset using tools like `image_dataset_from_directory`.\n",
        "### Split data into training, validation, and testing sets.\n",
        "\n",
        "`tf.keras.utils.image_dataset_from_directory(...)`  \n",
        "Used to load images from a directory where each subfolder represents a class.\n",
        "\n",
        "---\n",
        "\n",
        "**path**  \n",
        "Root directory path containing one subdirectory per class.\n",
        "\n",
        "**shuffle=True**  \n",
        "Randomly shuffles the image data. Useful during training to prevent the model from learning the order of the data.\n",
        "\n",
        "**image_size=(128, 128)**  \n",
        "Resizes all loaded images to this target size (width, height).  \n",
        "This must match the input size expected by the model.\n",
        "\n",
        "**batch_size=32**  \n",
        "Number of images per batch during training.  \n",
        "This affects memory usage and the frequency of model updates.\n",
        "\n",
        "**validation_split=False**  \n",
        "If set to a float (e.g., `0.2`), splits a portion of the data for validation.  \n",
        "If `False`, no split is applied.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Check GPU availability\n",
        "gpu_available = tf.config.list_physical_devices('GPU')\n",
        "print(\"GPU Available:\", gpu_available)\n"
      ],
      "metadata": {
        "id": "_eytdzoIeLgR"
      },
      "id": "_eytdzoIeLgR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d49e64d-8699-4851-8e6a-b74a510a3354",
      "metadata": {
        "id": "3d49e64d-8699-4851-8e6a-b74a510a3354"
      },
      "outputs": [],
      "source": [
        "datatest=tf.keras.utils.image_dataset_from_directory(testpath,shuffle = False, image_size = (128,128), batch_size = 32, validation_split= False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21926d08-21a7-41d5-b9c9-e9c63f4891dc",
      "metadata": {
        "id": "21926d08-21a7-41d5-b9c9-e9c63f4891dc"
      },
      "outputs": [],
      "source": [
        "datavalid = tf.keras.utils.image_dataset_from_directory(validpath,shuffle = True, image_size = (128,128), batch_size = 32, validation_split= False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06e1b50a-9d7d-4d04-8d14-b1595ac5c5ae",
      "metadata": {
        "id": "06e1b50a-9d7d-4d04-8d14-b1595ac5c5ae"
      },
      "outputs": [],
      "source": [
        "print(len(datatrain.class_names))\n",
        "class_names = datatrain.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b678dc32-3543-43af-8960-a9c895c4dfe5",
      "metadata": {
        "id": "b678dc32-3543-43af-8960-a9c895c4dfe5"
      },
      "source": [
        "### Visualize sample images from each class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53f27c9b-a1e1-4275-a5f2-aa053c8fd30f",
      "metadata": {
        "id": "53f27c9b-a1e1-4275-a5f2-aa053c8fd30f"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Set the size of the entire figure (width=10, height=10 inches)\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "# Take one batch from the dataset and iterate over the images and labels\n",
        "for images, labels in datatrain.take(1):\n",
        "    # Display the first 12 images from the batch\n",
        "    for i in range(12):\n",
        "        # Create a 4x3 grid of subplots and select the (i+1)th position\n",
        "        ax = plt.subplot(4, 3, i + 1)\n",
        "\n",
        "        # Display the image; convert the tensor to a NumPy array and ensure correct type\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "\n",
        "        # Set the title of the subplot to the class name of the image\n",
        "        plt.title(class_names[labels[i]])\n",
        "\n",
        "        # Remove axis ticks and labels for clarity\n",
        "        plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "niOSk32mfMx9"
      },
      "id": "niOSk32mfMx9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "3bf64c67-0105-499e-a592-0a67396c9fc2",
      "metadata": {
        "id": "3bf64c67-0105-499e-a592-0a67396c9fc2"
      },
      "source": [
        "- ## Check the number of images per class to ensure balance\n",
        "- ## Understand image properties like Image dimensions, Class labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "356ce7ec-6f3a-4b28-a85a-03da21f86675",
      "metadata": {
        "id": "356ce7ec-6f3a-4b28-a85a-03da21f86675"
      },
      "outputs": [],
      "source": [
        "def plot_class_distribution(dataset, title=\"Class Distribution\"):\n",
        "    \"\"\"\n",
        "    Plots the number of items per class in a given dataset.\n",
        "\n",
        "    Args:\n",
        "        dataset: A tf.data.Dataset object created using image_dataset_from_directory\n",
        "        title: Title for the plot (e.g., 'Train Data Distribution')\n",
        "    \"\"\"\n",
        "\n",
        "    class_counts = {}  # Dictionary to hold the count of each class\n",
        "\n",
        "    # Iterate through the batches in the dataset\n",
        "    for images, labels in dataset:\n",
        "        # Convert labels tensor to numpy array and loop through each label\n",
        "        for label in labels.numpy():\n",
        "            class_name = dataset.class_names[label]  # Get class name using label index\n",
        "            # Increment the count for this class\n",
        "            class_counts[class_name] = class_counts.get(class_name, 0) + 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b33b515-db94-4c14-bc9f-da6294713189",
      "metadata": {
        "id": "2b33b515-db94-4c14-bc9f-da6294713189"
      },
      "outputs": [],
      "source": [
        "\n",
        "    # Prepare data for plotting\n",
        "    class_names = list(class_counts.keys())  # List of class names\n",
        "    counts = list(class_counts.values())     # Corresponding counts for each class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2f28a42-1b4e-45f5-a37b-8e58c8c6a247",
      "metadata": {
        "id": "c2f28a42-1b4e-45f5-a37b-8e58c8c6a247"
      },
      "outputs": [],
      "source": [
        "\n",
        "    # Create the bar plot\n",
        "    plt.figure(figsize=(10, 6))  # Set the figure size\n",
        "    plt.bar(class_names, counts, color='skyblue')  # Draw bars with class counts\n",
        "    plt.xlabel(\"Class\")  # X-axis label\n",
        "    plt.ylabel(\"Number of Items\")  # Y-axis label\n",
        "    plt.title(title)  # Plot title\n",
        "    plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
        "    plt.tight_layout()  # Adjust layout to prevent clipping\n",
        "    plt.show()  # Display the plot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa48b945-c988-4587-8861-b9ceac028dfe",
      "metadata": {
        "id": "aa48b945-c988-4587-8861-b9ceac028dfe"
      },
      "outputs": [],
      "source": [
        "plot_class_distribution(datatrain, \"Training Data Distribution\")\n",
        "plot_class_distribution(datavalid, \"Validation Data Distribution\")\n",
        "plot_class_distribution(datatest, \"Test Data Distribution\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09248d7f-92d7-42a5-9550-d96379911db4",
      "metadata": {
        "id": "09248d7f-92d7-42a5-9550-d96379911db4"
      },
      "source": [
        "\n",
        "## 2.  Data Preprocessing / Preparation\n",
        "- Resize and rescale images.\n",
        "- Apply data augmentation (e.g., `RandomFlip`, `RandomRotation`, `RandomZoom`) to improve generalization.\n",
        "- Normalize images (using `preprocess_input` if using pre-trained models like EfficientNet)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71977780-ae06-40e1-8628-80060478edc6",
      "metadata": {
        "id": "71977780-ae06-40e1-8628-80060478edc6"
      },
      "outputs": [],
      "source": [
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "    tf.keras.layers.RandomRotation(0.1),\n",
        "    tf.keras.layers.RandomZoom(0.1),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c52c1522-5ee5-4650-8bf9-12beb6a3b119",
      "metadata": {
        "id": "c52c1522-5ee5-4650-8bf9-12beb6a3b119"
      },
      "source": [
        "\n",
        "## 3.  Model Selection\n",
        "- Choose a base model: Custom CNN or Transfer Learning (e.g., `EfficientNetV2B0`).\n",
        "- Decide whether to use pre-trained weights (e.g., ImageNet).\n",
        "- Define whether layers should be trainable or frozen during initial training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be3b0897-e892-410a-9c9f-333c79cee85c",
      "metadata": {
        "id": "be3b0897-e892-410a-9c9f-333c79cee85c"
      },
      "outputs": [],
      "source": [
        "base_model = tf.keras.applications.EfficientNetV2B0(\n",
        "    input_shape=(128, 128, 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:100]:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3608a9b9-5542-43f2-b978-4804b2d2cf23",
      "metadata": {
        "id": "3608a9b9-5542-43f2-b978-4804b2d2cf23"
      },
      "source": [
        "\n",
        "## 4.  Model Training\n",
        "- Build the model architecture using `Sequential` or Functional API.\n",
        "- Compile the model with loss function ( `sparse_categorical_crossentropy`), optimizer (e.g., `Adam`), and evaluation metrics (`accuracy`).\n",
        "\n",
        "## 5.  Model Tuning and Optimization\n",
        "- Tune hyperparameters: learning rate, batch size, number of layers, dropout rate.\n",
        "- Use callbacks: `EarlyStopping`,\n",
        "- Optionally perform fine-tuning on pre-trained models by unfreezing some layers."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40194586-8799-4ee0-83c4-692aa526b6cd",
      "metadata": {
        "id": "40194586-8799-4ee0-83c4-692aa526b6cd"
      },
      "source": [
        "### Model Architecture and Layer Utilities\n",
        "\n",
        "- **Sequential**: A simple way to build models by stacking layers one after the other in a linear fashion.\n",
        "\n",
        "- **RandomFlip**: A data augmentation layer that flips input images horizontally or vertically at random, helping the model generalize better.\n",
        "\n",
        "- **RandomRotation**: Randomly rotates images by a specified angle range during training to make the model invariant to orientation.\n",
        "\n",
        "- **RandomZoom**: Applies random zoom-in or zoom-out to training images, helping the model recognize objects at various scales.\n",
        "\n",
        "- **Dropout**: A regularization method that randomly \"drops\" (sets to zero) a fraction of input units during training to prevent overfitting.\n",
        "\n",
        "- **GlobalAveragePooling2D**: Reduces each feature map to a single number by taking the average, reducing model parameters and helping prevent overfitting.\n",
        "\n",
        "- **Dense**: A fully connected neural network layer used to learn complex features and typically found at the end of the model for classification.\n",
        "\n",
        "- **Input**: Specifies the input shape and data type for the model; acts as the starting point of the model architecture.\n",
        "\n",
        "- **EfficientNetV2B0**: A pre-trained convolutional neural network from the EfficientNetV2 family, known for being lightweight and high-performing, commonly used for transfer learning.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58a5e97f-d1bb-448f-bb40-9e996c8d069f",
      "metadata": {
        "id": "58a5e97f-d1bb-448f-bb40-9e996c8d069f"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(128, 128, 3)),\n",
        "    data_augmentation,\n",
        "    base_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),loss = tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['Accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cc4e897-6f87-4560-b1bf-b63717decd94",
      "metadata": {
        "id": "8cc4e897-6f87-4560-b1bf-b63717decd94"
      },
      "source": [
        "###  Callbacks\n",
        "- `EarlyStopping`: To stop training when validation performance stops improving."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a1fc0d5-0ba1-4227-bffe-f2a09999aeab",
      "metadata": {
        "id": "4a1fc0d5-0ba1-4227-bffe-f2a09999aeab"
      },
      "outputs": [],
      "source": [
        "# Define an EarlyStopping callback to stop training when validation loss stops improving\n",
        "early = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',            # Metric to monitor (validation loss here)\n",
        "    patience=3,                   # Number of epochs to wait after last improvement before stopping\n",
        "    restore_best_weights=True     # After stopping, restore the model weights from the epoch with the best val_loss\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df0d8e58-baf8-428b-a0a2-b150bd9c0a43",
      "metadata": {
        "id": "df0d8e58-baf8-428b-a0a2-b150bd9c0a43"
      },
      "source": [
        "### Train the model using `.fit()` with appropriate `epochs`, `batch_size`, and callbacks like `EarlyStopping`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89e70959-11fd-4f3a-8f27-1e339bbb1da4",
      "metadata": {
        "id": "89e70959-11fd-4f3a-8f27-1e339bbb1da4"
      },
      "outputs": [],
      "source": [
        "# Set the number of epochs to train the model\n",
        "epochs = 15\n",
        "\n",
        "# Train the model on the training dataset 'datatrain'\n",
        "history = model.fit(\n",
        "    datatrain,                      # Training data generator or dataset\n",
        "    validation_data=datavalid,      # Validation data generator or dataset\n",
        "    epochs=epochs,                  # Number of training epochs\n",
        "    batch_size=100,                 # Number of samples per gradient update\n",
        "    callbacks=[early]               # List of callbacks to apply during training (e.g., early stopping)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50c6e681-eb6d-440f-8cc3-91b2e307f4a4",
      "metadata": {
        "id": "50c6e681-eb6d-440f-8cc3-91b2e307f4a4"
      },
      "source": [
        "### Model Architechure of EfficientNETV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2578e13f-54a7-4e39-bb88-1493ae925571",
      "metadata": {
        "id": "2578e13f-54a7-4e39-bb88-1493ae925571"
      },
      "outputs": [],
      "source": [
        "model.summary() # Print the architecture summary of the  model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35f11049-e8f5-4446-ab9f-cb02e349cefe",
      "metadata": {
        "id": "35f11049-e8f5-4446-ab9f-cb02e349cefe"
      },
      "outputs": [],
      "source": [
        "base_model.summary() # Print the architecture summary of the base model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7aedc200-b200-4c4a-8cd6-fe6d93a1e556",
      "metadata": {
        "id": "7aedc200-b200-4c4a-8cd6-fe6d93a1e556"
      },
      "source": [
        "# Model Performance Visualization: Accuracy & Loss Trends"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65225b1a-2928-415c-b111-baf0b95215ac",
      "metadata": {
        "id": "65225b1a-2928-415c-b111-baf0b95215ac"
      },
      "outputs": [],
      "source": [
        "### Plotting Training and Validation Accuracy and Loss Over Epochs\n",
        "\n",
        "acc = history.history['Accuracy']           # Training accuracy\n",
        "val_acc = history.history['val_Accuracy']   # Validation accuracy\n",
        "loss = history.history['loss']              # Training loss\n",
        "val_loss = history.history['val_loss']      # Validation loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a6454f3-a408-4bac-a040-4c56892f6d34",
      "metadata": {
        "id": "2a6454f3-a408-4bac-a040-4c56892f6d34"
      },
      "outputs": [],
      "source": [
        "epochs_range = range(len(acc))              # X-axis range based on number of epochs\n",
        "\n",
        "plt.figure(figsize=(10, 8))                 # Set overall figure size\n",
        "\n",
        "plt.subplot(1, 2, 1)                        # 1 row, 2 columns, position 1\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')       # Plot training accuracy\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy') # Plot validation accuracy\n",
        "plt.legend(loc='lower right')              # Show legend at lower right\n",
        "plt.title('Training vs Validation Accuracy') # Set title for accuracy plot\n",
        "\n",
        "plt.subplot(1, 2, 2)                        # 1 row, 2 columns, position 2\n",
        "plt.plot(epochs_range, loss, label='Training Loss')          # Plot training loss\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')    # Plot validation loss\n",
        "plt.legend(loc='upper right')              # Show legend at upper right\n",
        "plt.title('Training vs Validation Loss')    # Set title for loss plot\n",
        "\n",
        "plt.show()                                  # Display the plots\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a52872ee-df87-422d-934d-7c8583c48072",
      "metadata": {
        "id": "a52872ee-df87-422d-934d-7c8583c48072"
      },
      "source": [
        "## 6.  Model Evaluation\n",
        "- Plot training and validation accuracy/loss curves.\n",
        "- Evaluate model performance on validation or test set.\n",
        "- Use metrics like:\n",
        "  - **Confusion Matrix**\n",
        "  - **Classification Report** (Precision, Recall, F1-score)\n",
        "  - `confusion_matrix`, `classification_report`: To evaluate the model's classification performance.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b77202a1-2f88-4630-baff-5cb2bbbd0670",
      "metadata": {
        "id": "b77202a1-2f88-4630-baff-5cb2bbbd0670"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(datatest)\n",
        "print(f'Test accuracy is{accuracy:.4f}, Test loss is {loss:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a802883-04da-4d76-a252-74ebe674f167",
      "metadata": {
        "id": "9a802883-04da-4d76-a252-74ebe674f167"
      },
      "outputs": [],
      "source": [
        "### Evaluate Model Performance on Test Data using Confusion Matrix and Classification Report\n",
        "\n",
        "# Extract true labels from all batches\n",
        "y_true = np.concatenate([y.numpy() for x, y in datatest], axis=0)  # Ground truth labels\n",
        "\n",
        "# Get predictions as probabilities and then predicted classes\n",
        "y_pred_probs = model.predict(datatest)\n",
        "\n",
        "# Class with highest probability\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# Print confusion matrix and classification report\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "print(classification_report(y_true, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcf4d7c8-ef4e-4d7f-95e6-e9af1dc538ad",
      "metadata": {
        "id": "dcf4d7c8-ef4e-4d7f-95e6-e9af1dc538ad"
      },
      "outputs": [],
      "source": [
        "### Plot Confusion Matrix as Heatmap for Better Visualization\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)                                     # Compute confusion matrix\n",
        "                                                     # Import seaborn for visualization\n",
        "\n",
        "plt.figure(figsize=(10, 8))                                               # Set figure size\n",
        "sns.heatmap(cm, annot=True, fmt='d',\n",
        "            xticklabels=class_names,\n",
        "            yticklabels=class_names,\n",
        "            cmap='Blues')                                                 # Create heatmap with class labels\n",
        "\n",
        "plt.xlabel('Predicted')                                                   # Label for x-axis\n",
        "plt.ylabel('True')                                                        # Label for y-axis\n",
        "plt.title('Confusion Matrix')                                             # Title for the plot\n",
        "plt.show()                                                                # Display the plot\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd242a44-fb20-4bab-b54d-df2f94674c4a",
      "metadata": {
        "id": "dd242a44-fb20-4bab-b54d-df2f94674c4a"
      },
      "source": [
        "## 7.  Final Testing and Save the Model\n",
        "- Evaluate the final model on the unseen **test dataset**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96ca972e-864e-4391-b9d0-c88004f6b48e",
      "metadata": {
        "id": "96ca972e-864e-4391-b9d0-c88004f6b48e"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c58835e-af97-4102-9ec0-ea2f0596839f",
      "metadata": {
        "id": "7c58835e-af97-4102-9ec0-ea2f0596839f"
      },
      "outputs": [],
      "source": [
        "### Display Sample Predictions: True Labels vs Predicted Labels\n",
        "\n",
        "class_names = datatest.class_names                                           # Get class names from test dataset\n",
        "\n",
        "for images, labels in datatest.take(1):                                     # Take one batch from test data\n",
        "    predictions = model.predict(images)                                     # Predict class probabilities\n",
        "    pred_labels = tf.argmax(predictions, axis=1)                            # Get predicted class indices\n",
        "\n",
        "    for i in range(8):                                                      # Display first 8 images from batch\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))                       # Convert tensor to image\n",
        "        plt.title(f\"True: {class_names[labels[i]]}, Pred: {class_names[pred_labels[i]]}\")  # Title with labels\n",
        "        plt.axis(\"off\")                                                     # Hide axes\n",
        "        plt.show()                                                          # Show image\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "252956f6-8d0b-44ff-a556-63ecdf588dd5",
      "metadata": {
        "id": "252956f6-8d0b-44ff-a556-63ecdf588dd5"
      },
      "source": [
        "**Save the trained model using `model.save()` or `save_model()` for future inference.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9655546d-3aca-4f2a-8fc0-4f9a3b2e1656",
      "metadata": {
        "id": "9655546d-3aca-4f2a-8fc0-4f9a3b2e1656"
      },
      "outputs": [],
      "source": [
        "# Save model in Keras format with architecture, weights, and training configuration\n",
        "model.save('Efficient_classify.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e8ef9fc-6a67-4365-a42e-c165c79e6ab9",
      "metadata": {
        "id": "5e8ef9fc-6a67-4365-a42e-c165c79e6ab9"
      },
      "outputs": [],
      "source": [
        "# Define your class labels\n",
        "class_names = ['Battery', 'Keyboard', 'Microwave', 'Mobile', 'Mouse', 'PCB', 'Player', 'Printer', 'Television', 'Washing Machine']\n",
        "\n",
        "# Load your Keras model\n",
        "model = tf.keras.models.load_model('Efficient_classify.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e9b9072-d5f8-46e8-b1a7-4d94ee3ba676",
      "metadata": {
        "id": "3e9b9072-d5f8-46e8-b1a7-4d94ee3ba676"
      },
      "source": [
        "\n",
        "## 8.  Model Deployment (Optional)\n",
        "- Create a web interface using **Gradio**.\n",
        "- Load the saved model and preprocess input images before prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d28e5779-6cd3-4051-9c31-89e05c33217a",
      "metadata": {
        "id": "d28e5779-6cd3-4051-9c31-89e05c33217a"
      },
      "outputs": [],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b042a43-3f6d-49ff-b978-baee00b7acc8",
      "metadata": {
        "id": "0b042a43-3f6d-49ff-b978-baee00b7acc8"
      },
      "source": [
        "### 🌐 Gradio Interface and Preprocessing\n",
        "- `gr`: To build a web interface for the model.\n",
        "- `PIL.Image`: For handling image input in Gradio.\n",
        "- `preprocess_input`: Preprocessing method for EfficientNet.\n",
        "- `load_model`: For loading a saved model for inference.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3048791-ef81-4727-9a4b-5aaafc884415",
      "metadata": {
        "id": "d3048791-ef81-4727-9a4b-5aaafc884415"
      },
      "outputs": [],
      "source": [
        "def classify_image(img):\n",
        "    # Step 1: Resize and convert to array\n",
        "    img = img.resize((128, 128))\n",
        "    img_array = np.array(img, dtype=np.float32)\n",
        "\n",
        "    # Step 2: Preprocess and add batch dimension\n",
        "    img_array = preprocess_input(img_array)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # Step 3: Predict using the model\n",
        "    prediction = model.predict(img_array)\n",
        "    index = np.argmax(prediction)  # Get index of highest score\n",
        "\n",
        "    # Step 4: Get class name and confidence\n",
        "    class_name = class_names[index]\n",
        "    confidence = prediction[0][index]\n",
        "\n",
        "    return f\"Predicted: {class_name} (Confidence: {confidence:.2f})\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ca7b85d-e440-4bdb-bfee-4a9e0cd29312",
      "metadata": {
        "id": "6ca7b85d-e440-4bdb-bfee-4a9e0cd29312"
      },
      "outputs": [],
      "source": [
        "# Create a Gradio interface for the classify_image function\n",
        "iface = gr.Interface(\n",
        "    fn=classify_image,          # The function to run when input is given\n",
        "    inputs=gr.Image(type=\"pil\"), # Input component: expects an image as a PIL object\n",
        "    outputs=\"text\"              # Output component: displays the result as plain text\n",
        ")\n",
        "\n",
        "# Launch the Gradio interface, opening a local web app to interact with the model\n",
        "iface.launch()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab4b8b4f-385a-4f21-ad60-f5e92db0ed56",
      "metadata": {
        "id": "ab4b8b4f-385a-4f21-ad60-f5e92db0ed56"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Summary: Trained CNN model for e-waste classification with 87% accuracy. Used Google Colab with GPU.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JV8SUzwNf3lB",
        "outputId": "453217c4-87b0-4263-9308-6d6724db0583"
      },
      "id": "JV8SUzwNf3lB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary: Trained CNN model for e-waste classification with 87% accuracy. Used Google Colab with GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fTr4mLGif421"
      },
      "id": "fTr4mLGif421",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}